{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "malnyunClone.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPuZuuni1+/UOjZ6Q7f8la1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dakyommii/study/blob/main/malnyunClone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iotS4F6zBKoH",
        "outputId": "6a6c03b3-903a-492d-83d0-5783d3ee14c2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGVAwZLNDYo1"
      },
      "source": [
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1nOFP5EBz8A"
      },
      "source": [
        "MODEL_SAVE_PATH = os.path.join(\"/content/drive/My Drive/results2\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSqtcH0mC4sj"
      },
      "source": [
        "DATA_PATH = \"/content/drive/My Drive/atoi_gan_fin\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqDLZRNvETfK",
        "outputId": "afef1893-f690-432d-aa86-93b5cd29fcb8"
      },
      "source": [
        "!git clone https://github.com/yu45020/Waifu2x.git"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Waifu2x'...\n",
            "remote: Enumerating objects: 546, done.\u001b[K\n",
            "remote: Total 546 (delta 0), reused 0 (delta 0), pack-reused 546\u001b[K\n",
            "Receiving objects: 100% (546/546), 138.07 MiB | 32.42 MiB/s, done.\n",
            "Resolving deltas: 100% (284/284), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8NbC3jGIjI5"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0,\"/content/Waifu2x\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dK2DJH3MDp1",
        "outputId": "65ed3b62-a82e-4f99-a372-a98e213d54d0"
      },
      "source": [
        "!ls /content/Waifu2x"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Common.py      examples\t\t Loss.py\t     Readme.md\n",
            "Dataloader.py  Img_to_Sqlite.py  model_check_points  train.py\n",
            "docs\t       LICENSE\t\t Models.py\t     utils\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxQHq4QyPWL_"
      },
      "source": [
        "!mkdir out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlLCoTouENWV"
      },
      "source": [
        "# for seed_idx, seed in enumerate(seeds):\n",
        "#         print('Generating image for seed %d/%d ...' % (seed_idx, len(seeds)))\n",
        "#         rnd = np.random.RandomState()\n",
        "#         tflib.set_vars({var: rnd.randn(*var.shape.as_list()) for var in noise_vars}) # [height, width]\n",
        "#         images = Gs.run(seed, None, **Gs_kwargs) # [minibatch, height, width, channel]\n",
        "#         path = f\"/content/drive/My Drive/results{seed_idx}.png\"\n",
        "#         PIL.Image.fromarray(images[0], 'RGB').save(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "rX7TTRQgB765",
        "outputId": "90ecb0fd-353f-416d-ab06-b83bdf67f40d"
      },
      "source": [
        "import utils\n",
        "import PIL\n",
        "from PIL import Image\n",
        "# from keras.preprocessing.image import load_img\n",
        "\n",
        "from utils.prepare_images import *\n",
        "from Models import *\n",
        "from torchvision.utils import save_image\n",
        "model_cran_v2 = CARN_V2(color_channels=3, mid_channels=64, conv=nn.Conv2d,\n",
        "                        single_conv_size=3, single_conv_group=1,\n",
        "                        scale=2, activation=nn.LeakyReLU(0.1),\n",
        "                        SEBlock=True, repeat_blocks=3, atrous=(1, 1, 1))\n",
        "                        \n",
        "model_cran_v2 = network_to_half(model_cran_v2)\n",
        "checkpoint = \"model_check_points/CRAN_V2/CARN_model_checkpoint.pt\"\n",
        "# model_cran_v2.load_state_dict(torch.load(checkpoint, 'fp16'))\n",
        "# if use GPU, then comment out the next line so it can use fp16. \n",
        "model_cran_v2 = model_cran_v2.float() \n",
        "\n",
        "file_name_in_dir = []\n",
        "\n",
        "for root,dirs,files in os.walk(DATA_PATH):\n",
        "  for fname in files:\n",
        "    full_fname=os.path.join(root,fname)\n",
        "    file_name_in_dir.append(full_fname)\n",
        "\n",
        "i = 0\n",
        "for file_image in file_name_in_dir:\n",
        "  i+=1\n",
        "  # demo_img = load_img(file_image)\n",
        "  # x=img_to_array(img)\n",
        "  # x=x.reshape((1,)+x.shape)\n",
        "\n",
        "  demo_img = f\"/content/drive/My Drive/atoi_gan_fin/IMG{i}.png\"\n",
        "  img = Image.open(demo_img).convert(\"RGB\")\n",
        "\n",
        "  # origin\n",
        "  img_t = to_tensor(img).unsqueeze(0) \n",
        "\n",
        "  # used to compare the origin\n",
        "  img = img.resize((img.size[0] // 2, img.size[1] // 2), Image.BICUBIC) \n",
        "\n",
        "  # overlapping split\n",
        "  # if input image is too large, then split it into overlapped patches \n",
        "  # details can be found at [here](https://github.com/nagadomi/waifu2x/issues/238)\n",
        "  img_splitter = ImageSplitter(seg_size=64, scale_factor=2, boarder_pad_size=3)\n",
        "  img_patches = img_splitter.split_img_tensor(img, scale_method=None, img_pad=0)\n",
        "  with torch.no_grad():\n",
        "      out = [model_cran_v2(k) for k in img_patches]\n",
        "  img_upscale = img_splitter.merge_img_tensor(out)\n",
        "\n",
        "  final = torch.cat([img_t, img_upscale])\n",
        "  save_image(final, f'out{i}.png', nrow=2)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-7fc7fc585a5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0mimg_upscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_splitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_img_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0mfinal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_upscale\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m   \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'out{i}.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: torch.cat(): Sizes of tensors must match except in dimension 0. Got 417 and 416 in dimension 2 (The offending index is 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK36TKi3CVna",
        "outputId": "26b1bd3c-ee2c-4139-d66e-163143be9e90"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyEleHvh_GiU",
        "outputId": "4dc0d19b-0b59-49fc-d0ce-5e920b60b586"
      },
      "source": [
        "# import tensorflow as tf\n",
        "# import sys\n",
        "# import os\n",
        "\n",
        "# sys.path.insert(0, \"/content/atoiGan\")\n",
        "\n",
        "# !git clone https://github.com/bryandlee/FreezeG.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'FreezeG' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU6BdTquBcdi",
        "outputId": "e8a24dcf-eca6-4346-f415-d5707c0d6c6d"
      },
      "source": [
        "# ! python create_dataset.py --src_dir='train' --dst_path='\"/content/drive/My Drive/results\"' --is_include_only_pos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python3: can't open file 'create_dataset.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}