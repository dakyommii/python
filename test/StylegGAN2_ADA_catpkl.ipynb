{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StylegGAN2-ADA_mon1",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dakyommii/study/blob/main/test/StylegGAN2_ADA_catpkl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87fN-d1-N9s0"
      },
      "source": [
        "# StyleGAN2-ADA 모델 학습하기\n",
        "\n",
        "이 노트북은 다음 노트북을 합쳐서 만들고 한글 설명을 추가했습니다.\n",
        "\n",
        "- https://colab.research.google.com/github/dvschultz/ml-art-colabs/blob/master/Stylegan2_ada_Custom_Training.ipynb\n",
        "- https://colab.research.google.com/github/Hephyrius/Stylegan2-Ada-Google-Colab-Starter-Notebook/blob/main/Stylegan2_Ada_Colab_Starter.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFB64iL9BzBd"
      },
      "source": [
        "StyleGAN2-ADA 모델은 텐서플로우 1 버전에서만 작동합니다. 아래 셀을 실행해서 1 버전을 사용할 수 있도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbyUpDO4OLiU",
        "outputId": "6d695141-a837-427f-dea0-6fbc818ca335"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91s4Bdk2CAJi"
      },
      "source": [
        "현재 구글에서 어떤 GPU를 할당받았는지 알아봅니다. 노트북 위의 메뉴에서 Runtime > Change runtime type 으로 가서 GPU가 선택되었는지 확인하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiBLUTr7OVoB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85d30073-4faf-4feb-897e-bd724ce2b090"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Nov 23 06:25:31 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhGEeUh8CEMc"
      },
      "source": [
        "내 구글 계정의 드라이브를 이 노트북과 연동시킵니다. 앞으로는 구글 드라이브의 파일을 노트북에서 가져다쓰거나, 노트북에서 생성된 파일들을 내 드라이브로 저장할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F46YSLmVOWWa",
        "outputId": "fd88bc26-aa9b-41b1-a4d0-7e348b3828ba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1jG7Cx1RWKY"
      },
      "source": [
        "## Clone StyleGAN2-ADA Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDEl_QC6CbDr"
      },
      "source": [
        "StyleGAN2-ADA 관련된 코드를 노트북으로 불러와서 다운로드받습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVtHBVKbOmKl",
        "outputId": "aa187bad-6550-41d9-99cd-eb10b8195dac"
      },
      "source": [
        "# Download the code\n",
        "%cd /content/\n",
        "!git clone https://github.com/dvschultz/stylegan2-ada.git\n",
        "!mkdir downloads\n",
        "!mkdir datasets"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'stylegan2-ada'...\n",
            "remote: Enumerating objects: 364, done.\u001b[K\n",
            "remote: Total 364 (delta 0), reused 0 (delta 0), pack-reused 364\u001b[K\n",
            "Receiving objects: 100% (364/364), 56.16 MiB | 26.17 MiB/s, done.\n",
            "Resolving deltas: 100% (200/200), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffxQiIkQRTGO"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa5ILnoJXNXq"
      },
      "source": [
        "이번 노트북에서 학습에 사용할 데이터는 포켓몬 이미지 데이터입니다. 다음 링크에서 다운로드받을 수 있습니다:\n",
        "\n",
        "https://www.kaggle.com/kvpratama/pokemon-images-dataset\n",
        "\n",
        "다운로드받은 파일은 각자의 구글 드라이브 폴더에 미리 업로드시켜주세요. 업로드한 후에는, 이 노트북에서 데이터를 불러와서 학습에 사용할 수 있습니다. 여기서는 포켓몬 데이터셋 (256x256)을 사용하지만, 다른 데이터셋으로 학습도 가능합니다.\n",
        "\n",
        "데이터셋의 이름을 zip파일 이름으로 바꿔주세요:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w637CVdoO3du"
      },
      "source": [
        "dataset_name = \"tiger-256\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NKBXJsUC1Cc"
      },
      "source": [
        "노트북으로 데이터셋 압축파일을 불러와서 압축을 풉니다. 왼쪽 Files에서 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tdy-VknQbkW"
      },
      "source": [
        "# import zipfile\n",
        "# path = \"/content/drive/MyDrive/Colab Notebooks/datasets/\"\n",
        "# dataset = dataset_name + \".zip\"\n",
        "# local_path = \"/content/\"\n",
        "# file_name = path + dataset\n",
        "# with zipfile.ZipFile(file_name, 'r') as zip:\n",
        "#    #zip.printdir()\n",
        "#    print('Extracting all the files now...') \n",
        "#    zip.extractall(local_path) \n",
        "#    print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxtOLRCvDULH"
      },
      "source": [
        "불러온 이미지 데이터셋 jpg 파일들을 텐서플로에서 사용할 수 있는 데이터셋 포맷(tfrecords)으로 바꿔줍니다. 이 변환과정이 데이터셋의 크기에 따라 굉장히 오래 걸릴 수 있습니다. 이미지 파일들이 저장되어있는 경로를 잘 설정해줘야합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlS7sB4xQtmC",
        "outputId": "0c1a004f-f7c4-4672-848a-2f17d1a2d756",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /content/\n",
        "\n",
        "#update this to the path to your image folder\n",
        "dataset_folder_name = 'pokemon_jpg/pokemon_jpg' # name of zip file may be different from folder name it extracted to\n",
        "dataset_path = \"/content/drive/MyDrive/datasets/tiger-256\" \n",
        "\n",
        "#you don't need to edit anything here\n",
        "# %cd /content/drive/MyDrive/colab-sg2-ada/stylegan2-ada\n",
        "# !python dataset_tool.py create_from_images/content/drive/MyDrive/datasets/{dataset_name} {dataset_path}"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyhe_tggRPnq"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrikBYS-VOnO"
      },
      "source": [
        "학습할 때 우리가 조절할 수 있는 다양한 패러미터들이 있습니다. 다음 셀을 실행하면 도움말을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPPicfQXQ_PZ"
      },
      "source": [
        "# %cd /content/drive/MyDrive/colab-sg2-ada/stylegan2-ada\n",
        "# !python train.py --help"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhlt3UUwVWmg"
      },
      "source": [
        "아래 셀을 실행하면 학습이 시작됩니다. **학습이 진행되는 동안에는, 이 노트북 창을 열어두어야 합니다.** 노트북 창을 닫거나 인터넷 연결이 끊기면, 콜랩 노트북의 실행이 중단됩니다. 또, 너무 오랜시간동안 실행되고 있는 노트북은 구글에서 자동으로 차단합니다. 연결이 끊긴 경우에는 이 노트북을 처음 셀부터 다시 실행해야합니다. 연결이 끊긴 후에 이어서 학습을 하고 싶은 경우에는 `resume_from` 경로를 최근의 `pkl` 파일 경로로 바꿔주세요.\n",
        "\n",
        "학습이 진행되는 동안 구글 드라이브 폴더를 확인해보세요. 중간 과정의 이미지 결과물과 모델을 자동으로 저장합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yo53TCYVRKW0",
        "outputId": "84a9b866-40b0-47dc-db45-3f714a87f54c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# output directory\n",
        "output_dir = '/content/drive/MyDrive/result/tiger-256' \n",
        "\n",
        "# config\n",
        "config = \"auto\"\n",
        "\n",
        "# gamma\n",
        "gamma = 1\n",
        "\n",
        "#how often should the model generate samples and a .pkl file\n",
        "snapshot_count = 1\n",
        "\n",
        "#should the images be mirrored left to right?\n",
        "mirrored = True\n",
        "#should the images be mirrored top to bottom?\n",
        "mirroredY = False\n",
        "\n",
        "#metrics? \n",
        "metric_list = None\n",
        "#\n",
        "# this is the most important cell to update\n",
        "#\n",
        "# running it for the first time? set it to ffhq(+resolution)\n",
        "# resuming? get the path to your latest .pkl file and use that\n",
        "resume_from = \"/content/drive/MyDrive/ckpt/network-snapshot-000004.pkl\"\n",
        "\n",
        "# make sure there is no space in the resume path. if there is any, use a backslash character to escape\n",
        "#resume_from = '/content/drive/MyDrive/Colab\\ Notebooks/results/pokemon-256/00000-pokemon-256-mirror-auto1-gamma1-resumeffhq256/network-snapshot-000044.pkl'\n",
        "\n",
        "#don't edit this unless you know what you're doing :)\n",
        "!python train.py --outdir={output_dir} \\\n",
        "                 --cfg={config} \\\n",
        "                 --snap={snapshot_count} \\\n",
        "                 --data=/content/drive/MyDrive/datasets/{dataset_name} \\\n",
        "                 --mirror={mirrored} --mirrory={mirroredY} \\\n",
        "                 --gamma={gamma} \\\n",
        "                 --metrics={metric_list} \\\n",
        "                 --resume={resume_from}"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'train.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ioiZs5aF66S",
        "outputId": "a75ca427-02e8-4d0b-a78b-68a7ecb3ef25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd \"/content/stylegan2-ada\"\n",
        "!python '/content/stylegan2-ada/train.py' --outdir=out --trunc=0.5 --styles=0-8 --rows=8,16,26 --cols=39,44,49 --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/afhqcat.pkl"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/colab-sg2-ada/stylegan2-ada'\n",
            "/content\n",
            "usage: train.py [-h] --outdir DIR [--gpus INT] [--snap INT] [--seed INT] [-n]\n",
            "                --data PATH [--res INT] [--mirror BOOL] [--mirrory BOOL]\n",
            "                [--use-raw BOOL] [--metrics LIST] [--metricdata PATH]\n",
            "                [--cfg {auto,11gb-gpu,11gb-gpu-complex,24gb-gpu,24gb-gpu-complex,48gb-gpu,48gb-2gpu,stylegan2,paper256,paper512,paper1024,cifar,cifarbaseline,aydao}]\n",
            "                [--lrate FLOAT] [--ttur BOOL] [--gamma FLOAT] [--nkimg INT]\n",
            "                [--kimg INT] [--topk FLOAT] [--aug {noaug,ada,fixed,adarv}]\n",
            "                [--p FLOAT] [--target TARGET] [--initstrength INITSTRENGTH]\n",
            "                [--augpipe {blit,geom,color,filter,noise,cutout,bg,bgc,bgcf,bgcfn,bgcfnc}]\n",
            "                [--cmethod {nocmethod,bcr,zcr,pagan,wgangp,auxrot,spectralnorm,shallowmap,adropout}]\n",
            "                [--dcap FLOAT] [--resume RESUME] [--freezed INT]\n",
            "train.py: error: the following arguments are required: --data\n"
          ]
        }
      ]
    }
  ]
}